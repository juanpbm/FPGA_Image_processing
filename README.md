# Image Processing Optimization Using Pynq FPGA
## Author: Juan Pablo Bernal

Computer vision has been evolving rapidly in the last two decades. It is being used in a wide range of applications including sensing and navigation, object recognition and tracking, security, and much more. All these require basic image processing to improve the quality of your input data and get better results. The main problem is that image processing involves a lot of repetitive tasks that can get very computationally expensive. When working with software, the complex architecture of a CPU can negatively affect the efficiency of the algorithms. Therefore, in this project, we are going to explore different approaches on an FPGA to improve the processing time of different computer vision techniques.

This project is focused on optimizing spatial filtering using the Pynq FPGA. The first step in image processing is normally noise reduction to increase the quality of the data. This can be achieved by convolving an image with a smoothing spatial filter. Many different filters can achieve this goal, however, in this project, we only explored averaging and median filters. An averaging filter works by replacing the value of each pixel with the average of the pixels in a window around it. A median filter works similarly but instead of the average, the pixel is replaced with the median value of the window around it. the size of the filter dictates how many pixels will be used to compute the new values. To explore the effect the size of the filter has on the performance, two averaging filters and two median filters were used; each of size 7 and 21 respectively.

For more detailed information about this project please refer to the [Project Report](https://github.com/juanpbm/FPGA_Image_processing/blob/main/Information%20About%20the%20Project/Report.pdf)

### Source Code Running Instructions:
The image processing [Jupiter notebooks](https://github.com/juanpbm/FPGA_Image_processing/tree/main/Jupyter%20Notebooks) can be run without any special instructions. To run the HLS C++ [testbench](https://github.com/juanpbm/FPGA_Image_processing/blob/main/sources/img1_proc_test.cpp) each filter must be run individually. For this uncomment the desired filter and comment the others in lines 32 to 39. Each filter is composed of two lines the filter function and the golden output file. Remember to have the txt files in the same folder as the C++ script. Make sure that both lines are uncommented for the desired filter. Moreover, only add the header file for the desired filter in lines 3 to 6. This test file will compare the golden output to the function output. If there is a single wrong value, it will print “Failed at <index of the first wrong value>” otherwise it will print “PASS: The output matches the golden output”. To run the project on hardware, place the folder [overlays](https://github.com/juanpbm/FPGA_Image_processing/tree/main/overlays) in the Pyinq board. Similarly, if you want to generate the bitstream or the block design in Vivado use the tcl and hwh files found in the overlays folder. 
